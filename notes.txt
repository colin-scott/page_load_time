---------------- TODO: ------------------

- Figure out how to parralelize fetching?

- Understand why replay (broken_wpr_log.txt) took 30 sec, whereas original
  took ~1 sec.

- Graph difference between original PLT and replay PLT?

---------------- Questions: ------------------

Would it be advantageous to have PhantomJS emulate a particular browser? (Is
that possible?)

Do we have an estimate on what cache hit ratio prefetch/preconnect achieve in
practice? Obviously not 100%, as we're assuming for the analysis.

--------------- Installation: --------------

brew update && brew install phantomjs
cd analysis && git clone git@github.com:colin-scott/web-page-replay.git wpr

-------------- Workflow: ----------------

./data/csv/extract_urls.rb httparchive*pages.csv > ../target_urls
cd data
sudo ./data/fetch_urls_sequentially.py
cd ..
./analysis/wpr/modify_wpr_delays.py ./data/wpr
cd data
sudo ./replay_urls_sequentially.py ./data/wpr
cd ../analysis
./har_processing/extract_plt.rb ../data/replay > plts.dat
cd graphs/percent_plt_reduction
./compute_median_reduction.rb ../../plts.dat > percent_reduction.dat
./generate_cdf_from_raw_data.sh percent_reduction.dat

# Other graphs
cd ../../
./har_processing/extract_cacheable_bytes.rb ../data/replay > cacheable_bytes.dat
./graphs/cacheable_bytes/generate_cdf_from_raw_data.sh cacheable_bytes.dat
./graphs/total_bytes/generate_cdf_from_raw_data.sh cacheable_bytes.dat













*********** OLD (httparchive.org) NOTES **************

It's the `requests` table that includes responses headers, not the `pages`
table.

The `stats` (and `pages`?) table has the original onLoad time.

Small problem: many of the HAR files aren't fetchable from httparchive.org.
The web server responds with a 200, but no body.

May not be able to get historical data for before 2012:
"Jul 1 2012 - The HTTP
Archive Mobile switched from running on the Blaze.io framework to WebPagetest.
This involved several changes including new iPhone hardware (although both
used iOS5) and a new geo location (from Toronto to Redwood City)."

-------------- Questions: --------------

Does WPR delay DNS requests?

Does WPR insert the original delays by default? -> Yes, but the original
execution isn't that close to the replayed. Although, when repeatedly
replaying, the results are fairly consistent. Plan: get the original PLT by
replaying, not by mining it directly from the HAR. This also solves the IE
prolem.

Does HAR have enough of the response body content to be able to replay? -> Not
sure about Flash/Video.

Are the HTTP Archives complete enough to be able to replay with WPR? Email
response said something about javascript injection (deterministic.js).

-------------- Implementation notes: --------------

- Might need to get webkit-headless running. (Although, it was IE that did the
  original web page loads?)

http://dsalzr.wordpress.com/2012/08/10/theres-still-no-perfect-headless-browser/
http://stackoverflow.com/questions/9210765/any-way-to-start-google-chrome-in-headless-mode
There's also WPT.

- It is possible to get individual HAR files, by issuing queries to:

http://httparchive.webpagetest.org/export.php?test=$wptid&run=$wptrun&bodies=1&pretty=0

using the wptid and wptrun values in the Pages table

- Need to join the `time` field of the original request with the `time` field of
the responses to get the relative timings.

--------------- Workflow ---------------------

./data/fetch_har_files.rb /path/to/httparchive_pages.csv
./analysis/modify_all_hars.sh data/har/*har
./analysis/convert_all_hars.sh data/har/*har
for F in data/wpr/*
  sudo ./analysis/wpr/replay.py --use_server_delays $F
  # Load webpage
done

-------------- Tools: --------------

WPR:

https://github.com/chromium/web-page-replay

HTTP Archive Downloads:

http://httparchive.org/downloads.php

HAR format:

http://www.softwareishard.com/blog/har-12-spec/

Existing BigQuery queries:

http://bigqueri.es/t/getting-started-with-bigquery-http-archive/2

Query on cache-control policy:

http://bigqueri.es/t/cache-control-response-policy-of-html-documents/310
